{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic MLP experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x245d51e42e8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from typing import List\n",
    "\n",
    "torch.manual_seed(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transform = transforms.ToTensor()\n",
    "train = datasets.MNIST(root=\"../\", train=True, download=False, transform=Transform)\n",
    "test = datasets.MNIST(root=\"../\", train=False, download=False, transform=Transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 100\n",
    "TEST_BATCH_SIZE = 500\n",
    "train_loader = DataLoader(train, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test, batch_size=TEST_BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size: int, output_size: int, layer_sizes: List[int]):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.layers = [\n",
    "            nn.Linear(self.input_size, layer_sizes[0]),\n",
    "            nn.ReLU(),\n",
    "        ]\n",
    "        for i in range(1, len(layer_sizes)):\n",
    "            previous_layer_size = layer_sizes[i-1]\n",
    "            current_layer_size = layer_sizes[i]\n",
    "            new_layer = nn.Linear(previous_layer_size, current_layer_size)\n",
    "            self.layers.append(new_layer)\n",
    "            self.layers.append(nn.ReLU())\n",
    "        \n",
    "        output_layer = nn.Linear(layer_sizes[-1], output_size)\n",
    "        self.layers.append(output_layer)\n",
    "        self.layers.append(nn.LogSoftmax(dim=1))\n",
    "        self.model = nn.Sequential(*self.layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(\n",
    "    input_size = 784,\n",
    "    output_size = 10, \n",
    "    layer_sizes = [100, 100]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/10, \n",
      "                batch: 200, \n",
      "                train loss: 0.09538207948207855, \n",
      "                train accuracy: 0.9718000292778015\n",
      "epoch: 1/10, \n",
      "                batch: 400, \n",
      "                train loss: 0.04335453361272812, \n",
      "                train accuracy: 0.9724000096321106\n",
      "epoch: 1/10, \n",
      "                batch: 600, \n",
      "                train loss: 0.0526336245238781, \n",
      "                train accuracy: 0.9730499982833862\n",
      "TEST STEP for epoch 20 || accuracy: 0.9702000021934509\n",
      "epoch: 2/10, \n",
      "                batch: 200, \n",
      "                train loss: 0.1058955118060112, \n",
      "                train accuracy: 0.9772999882698059\n",
      "epoch: 2/10, \n",
      "                batch: 400, \n",
      "                train loss: 0.11305034905672073, \n",
      "                train accuracy: 0.9779000282287598\n",
      "epoch: 2/10, \n",
      "                batch: 600, \n",
      "                train loss: 0.09886480122804642, \n",
      "                train accuracy: 0.9777166843414307\n",
      "TEST STEP for epoch 20 || accuracy: 0.975600004196167\n",
      "epoch: 3/10, \n",
      "                batch: 200, \n",
      "                train loss: 0.020664434880018234, \n",
      "                train accuracy: 0.9819999933242798\n",
      "epoch: 3/10, \n",
      "                batch: 400, \n",
      "                train loss: 0.025173425674438477, \n",
      "                train accuracy: 0.9818249940872192\n",
      "epoch: 3/10, \n",
      "                batch: 600, \n",
      "                train loss: 0.051961641758680344, \n",
      "                train accuracy: 0.9820666909217834\n",
      "TEST STEP for epoch 20 || accuracy: 0.972599983215332\n",
      "epoch: 4/10, \n",
      "                batch: 200, \n",
      "                train loss: 0.03123576007783413, \n",
      "                train accuracy: 0.9857000112533569\n",
      "epoch: 4/10, \n",
      "                batch: 400, \n",
      "                train loss: 0.07017853111028671, \n",
      "                train accuracy: 0.9856500029563904\n",
      "epoch: 4/10, \n",
      "                batch: 600, \n",
      "                train loss: 0.016906147822737694, \n",
      "                train accuracy: 0.9852333068847656\n",
      "TEST STEP for epoch 20 || accuracy: 0.9783999919891357\n",
      "epoch: 5/10, \n",
      "                batch: 200, \n",
      "                train loss: 0.06353706866502762, \n",
      "                train accuracy: 0.988349974155426\n",
      "epoch: 5/10, \n",
      "                batch: 400, \n",
      "                train loss: 0.04956921935081482, \n",
      "                train accuracy: 0.9877750277519226\n",
      "epoch: 5/10, \n",
      "                batch: 600, \n",
      "                train loss: 0.008433826267719269, \n",
      "                train accuracy: 0.9872333407402039\n",
      "TEST STEP for epoch 20 || accuracy: 0.9772999882698059\n",
      "epoch: 6/10, \n",
      "                batch: 200, \n",
      "                train loss: 0.047438785433769226, \n",
      "                train accuracy: 0.9907500147819519\n",
      "epoch: 6/10, \n",
      "                batch: 400, \n",
      "                train loss: 0.03628268092870712, \n",
      "                train accuracy: 0.9896500110626221\n",
      "epoch: 6/10, \n",
      "                batch: 600, \n",
      "                train loss: 0.022890128195285797, \n",
      "                train accuracy: 0.9889500141143799\n",
      "TEST STEP for epoch 20 || accuracy: 0.9740999937057495\n",
      "epoch: 7/10, \n",
      "                batch: 200, \n",
      "                train loss: 0.007131635677069426, \n",
      "                train accuracy: 0.9912999868392944\n",
      "epoch: 7/10, \n",
      "                batch: 400, \n",
      "                train loss: 0.04979252442717552, \n",
      "                train accuracy: 0.9914500117301941\n",
      "epoch: 7/10, \n",
      "                batch: 600, \n",
      "                train loss: 0.003418584819883108, \n",
      "                train accuracy: 0.9911166429519653\n",
      "TEST STEP for epoch 20 || accuracy: 0.9778000116348267\n",
      "epoch: 8/10, \n",
      "                batch: 200, \n",
      "                train loss: 0.02756761573255062, \n",
      "                train accuracy: 0.9930999875068665\n",
      "epoch: 8/10, \n",
      "                batch: 400, \n",
      "                train loss: 0.03929854556918144, \n",
      "                train accuracy: 0.9927250146865845\n",
      "epoch: 8/10, \n",
      "                batch: 600, \n",
      "                train loss: 0.006383874453604221, \n",
      "                train accuracy: 0.9924833178520203\n",
      "TEST STEP for epoch 20 || accuracy: 0.977400004863739\n",
      "epoch: 9/10, \n",
      "                batch: 200, \n",
      "                train loss: 0.015715306624770164, \n",
      "                train accuracy: 0.9941499829292297\n",
      "epoch: 9/10, \n",
      "                batch: 400, \n",
      "                train loss: 0.010249065235257149, \n",
      "                train accuracy: 0.9929500222206116\n",
      "epoch: 9/10, \n",
      "                batch: 600, \n",
      "                train loss: 0.024177826941013336, \n",
      "                train accuracy: 0.9923666715621948\n",
      "TEST STEP for epoch 20 || accuracy: 0.9768999814987183\n",
      "epoch: 10/10, \n",
      "                batch: 200, \n",
      "                train loss: 0.02272712253034115, \n",
      "                train accuracy: 0.9962000250816345\n",
      "epoch: 10/10, \n",
      "                batch: 400, \n",
      "                train loss: 0.031926415860652924, \n",
      "                train accuracy: 0.9952750205993652\n",
      "epoch: 10/10, \n",
      "                batch: 600, \n",
      "                train loss: 0.023715289309620857, \n",
      "                train accuracy: 0.9944499731063843\n",
      "TEST STEP for epoch 20 || accuracy: 0.9764000177383423\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_correct = []\n",
    "test_correct = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_train_accurate = 0\n",
    "    epoch_test_accurate = 0\n",
    "    for i, (image, label) in enumerate(train_loader):\n",
    "        prediction_vector = model(image.view(TRAIN_BATCH_SIZE, -1))\n",
    "        loss = criterion(prediction_vector, label)\n",
    "        predicted_class = torch.max(prediction_vector, 1)[1]\n",
    "        batch_accurate = (predicted_class == label).sum()\n",
    "        epoch_train_accurate += batch_accurate\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 200 == 199:\n",
    "            print(\n",
    "                f\"\"\"epoch: {epoch+1}/{EPOCHS}, \n",
    "                batch: {i+1}, \n",
    "                train loss: {loss.item()}, \n",
    "                train accuracy: {epoch_train_accurate/((i+1) * TRAIN_BATCH_SIZE)}\"\"\"\n",
    "            )\n",
    "    train_losses.append(loss)\n",
    "    train_correct.append(epoch_train_accurate)\n",
    "    with torch.no_grad():\n",
    "        for i, (image, label) in enumerate(test_loader):\n",
    "            prediction_vector = model(image.view(TEST_BATCH_SIZE, -1))\n",
    "            predicted_class = torch.max(prediction_vector.data, 1)[1]\n",
    "            epoch_test_accurate += (predicted_class == label).sum()\n",
    "    test_correct.append(epoch_test_accurate)\n",
    "    print(f\"TEST STEP for epoch {epoch+1} || accuracy: {epoch_test_accurate/10000}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
